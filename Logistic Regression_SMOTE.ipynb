{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004d5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file only runs the logistic regression implemented by us and by sklearn with SMOTE oversampling \n",
    "# Need \"cleaned_K8.csv\" to be in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8685878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcd64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_K8.csv\", header = None, low_memory = False)  # process the data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f733920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc559e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5399</th>\n",
       "      <th>5400</th>\n",
       "      <th>5401</th>\n",
       "      <th>5402</th>\n",
       "      <th>5403</th>\n",
       "      <th>5404</th>\n",
       "      <th>5405</th>\n",
       "      <th>5406</th>\n",
       "      <th>5407</th>\n",
       "      <th>5408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5409 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9     ...  \\\n",
       "0 -0.161 -0.014  0.002 -0.036 -0.033 -0.093  0.025  0.005  0.000 -0.015  ...   \n",
       "1 -0.158 -0.002 -0.012 -0.025 -0.012 -0.106  0.013  0.005  0.000 -0.002  ...   \n",
       "2 -0.169 -0.025 -0.010 -0.041 -0.045 -0.069  0.038  0.014  0.008 -0.014  ...   \n",
       "3 -0.183 -0.051 -0.023 -0.077 -0.092 -0.015  0.071  0.027  0.020 -0.019  ...   \n",
       "4 -0.154  0.005 -0.011 -0.013 -0.002 -0.115  0.005  0.002 -0.003  0.002  ...   \n",
       "\n",
       "    5399   5400   5401   5402   5403   5404   5405   5406   5407  5408  \n",
       "0  0.006  0.013  0.021  0.020  0.016 -0.011  0.003  0.010 -0.007     0  \n",
       "1  0.002 -0.008  0.007  0.015 -0.008 -0.011 -0.004  0.013  0.005     0  \n",
       "2  0.019  0.010  0.025  0.025  0.021 -0.012  0.006  0.016 -0.018     0  \n",
       "3  0.051  0.012  0.050  0.038  0.051 -0.015  0.017  0.027 -0.049     0  \n",
       "4 -0.011  0.012  0.009  0.003 -0.001  0.002 -0.006  0.009  0.013     0  \n",
       "\n",
       "[5 rows x 5409 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe6bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the X and y from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882e84f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of X (16592, 5408)\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [x for x in range(5408)]\n",
    "X = df[feature_cols]\n",
    "y = df[5408]\n",
    "print(\"dimensions of X\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1790af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionHand:\n",
    "    def __init__(self, learn_rate = 0.001, num_iters=10000):\n",
    "        self.learn_rate = learn_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.W = None \n",
    "        self.bias = None\n",
    "    \n",
    "    # X is num_samples by num_features \n",
    "    # y is 1D row vector for each training sample\n",
    "    def fit(self, X, y):\n",
    "        # init params (as zeros)\n",
    "        num_samples, num_features = X.shape\n",
    "        self.W = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # gradient descent\n",
    "        for i in range(self.num_iters):\n",
    "            linear_model = np.dot(X, self.W) + self.bias \n",
    "            \n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "            \n",
    "            # derivatives\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
    "            \n",
    "            # update weights and bias \n",
    "            self.W -= self.learn_rate * dw\n",
    "            self.bias -= self.learn_rate * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.W) + self.bias \n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        \n",
    "        # based on y_predicted, get the predicted class label\n",
    "        y_predicted_label = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        \n",
    "        return y_predicted_label\n",
    "    \n",
    "    # sigmoid func\n",
    "    def _sigmoid(self, x):\n",
    "        sigmoid = 1 / (1 + np.exp(-x))\n",
    "        return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181ca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate accuracy \n",
    "def accuracy(y_observed, y_predicted):\n",
    "    accuracy = np.sum(y_observed == y_predicted) / len(y_observed)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f85647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the imbalanced data, only using SMOTE oversampling technique\n",
    "def process_imb_data(X, y, testSize):\n",
    "    # only oversampling begin\n",
    "    over = SMOTE()\n",
    "    \n",
    "    # use train_test_split function to randomly split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state = 1234)\n",
    "    \n",
    "    X_smote, y_smote = over.fit_resample(X_train, y_train)\n",
    "    smote_count_1 = 0\n",
    "    smote_count_0 = 0\n",
    "\n",
    "    for i in y_smote:\n",
    "        if i == 1:\n",
    "            smote_count_1 += 1\n",
    "        elif i == 0:\n",
    "            smote_count_0 += 1\n",
    "    #print(\"smote_count_1, smote_count_0\", smote_count_1, smote_count_0)\n",
    "    \n",
    "    return X_smote, y_smote, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a6d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs logistic regression (sklearn implementation) with parameter: testSize, \n",
    "def LogisticRegression_package(X, y, testSize):\n",
    "    X_train_smote, y_train_smote, X_test, y_test = process_imb_data(X, y, testSize)\n",
    "    # use train_test_split function to randomly split the data into training and testing data\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state = 1234)\n",
    "    clf = LogisticRegression(max_iter = 10000)\n",
    "    clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_predictions = clf.predict(X_test)\n",
    "    print(\"\")\n",
    "    print(\"For SMOTE with LR from sklearn package:\")\n",
    "    print(\"Logistic classification accurary:\", accuracy(y_test, y_predictions))\n",
    "    print(\"precision_score\", precision_score(y_test, y_predictions))\n",
    "    print(\"recall_score\", recall_score(y_test, y_predictions))\n",
    "    print(\"f1_score\", f1_score(y_test, y_predictions))\n",
    "    print(\"roc_auc_score\", roc_auc_score(y_test, y_predictions))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_predictions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd45e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_package_lasso(X, y, testSize):\n",
    "    X_train_smote, y_train_smote, X_test, y_test = process_imb_data(X, y, testSize)\n",
    "    clf = LogisticRegression(penalty='l1', solver='liblinear', max_iter = 10000)\n",
    "    clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    y_predictions = clf.predict(X_test)\n",
    "    print(\"\")\n",
    "    print(\"For SMOTE + logistic regression from sklearn package:\")\n",
    "    print(\"Logistic classification accurary:\", accuracy(y_test, y_predictions))\n",
    "    print(\"precision_score\", precision_score(y_test, y_predictions))\n",
    "    print(\"recall_score\", recall_score(y_test, y_predictions))\n",
    "    print(\"f1_score\", f1_score(y_test, y_predictions))\n",
    "    print(\"roc_auc_score\", roc_auc_score(y_test, y_predictions))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_predictions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35519d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs logistic regression (our implementation) with parameter: testSize, \n",
    "def LogisticRegression_calc(X, y, testSize):\n",
    "    # first process the imbalanced data for training\n",
    "    X_train_smote, y_train_smote, X_test, y_test = process_imb_data(X, y, testSize)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state = 1234)\n",
    "    Logistic_regressor = LogisticRegressionHand(learn_rate = 0.001, num_iters=10000)\n",
    "    Logistic_regressor.fit(X_train_smote, y_train_smote)\n",
    "    y_predictions = Logistic_regressor.predict(X_test)\n",
    "    print(\"\")\n",
    "    print(\"Training after SMOTE with logistic regression implemented by hand:\")\n",
    "    print(\"Logistic classification accurary:\", accuracy(y_test, y_predictions))\n",
    "    print(\"precision_score\", precision_score(y_test, y_predictions))\n",
    "    print(\"recall_score\", recall_score(y_test, y_predictions))\n",
    "    print(\"f1_score\", f1_score(y_test, y_predictions))\n",
    "    print(\"roc_auc_score\", roc_auc_score(y_test, y_predictions))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_predictions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c38283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote_count_1, smote_count_0 11517 11517\n",
      "\n",
      "Training after SMOTE with logistic regression implemented by hand:\n",
      "Logistic classification accurary: 0.9825231016472479\n",
      "precision_score 0.3119266055045872\n",
      "recall_score 0.7391304347826086\n",
      "f1_score 0.4387096774193548\n",
      "roc_auc_score 0.8619618110652703\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression on original data \n",
    "LogisticRegression_calc(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ab074e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote_count_1, smote_count_0 11517 11517\n",
      "\n",
      "For SMOTE with LR from sklearn package:\n",
      "Logistic classification accurary: 0.9841301727601446\n",
      "precision_score 0.3058823529411765\n",
      "recall_score 0.5652173913043478\n",
      "f1_score 0.39694656488549623\n",
      "roc_auc_score 0.7766273493423604\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use sklearn package \n",
    "LogisticRegression_package(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affa475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
